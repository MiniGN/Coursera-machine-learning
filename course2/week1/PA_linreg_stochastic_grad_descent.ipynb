{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия и стохастический градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание основано на материалах лекций по линейной регрессии и градиентному спуску. Вы будете прогнозировать выручку компании в зависимости от уровня ее инвестиций в рекламу по TV, в газетах и по радио."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вы научитесь:\n",
    "- решать задачу восстановления линейной регрессии\n",
    "- реализовывать стохастический градиентный спуск для ее настройки\n",
    "- решать задачу линейной регрессии аналитически"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение\n",
    "Линейная регрессия - один из наиболее хорошо изученных методов машинного обучения, позволяющий прогнозировать значения количественного признака в виде линейной комбинации прочих признаков с параметрами - весами модели. Оптимальные (в смысле минимальности некоторого функционала ошибки) параметры линейной регрессии можно найти аналитически с помощью нормального уравнения или численно с помощью методов оптимизации.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная регрессия использует простой функционал качества - среднеквадратичную ошибку. Мы будем работать с выборкой, содержащей 3 признака. Для настройки параметров (весов) модели решается следующая задача:\n",
    "$$\\Large \\frac{1}{\\ell}\\sum_{i=1}^\\ell{{((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}^2} \\rightarrow \\min_{w_0, w_1, w_2, w_3},$$\n",
    "где $x_{i1}, x_{i2}, x_{i3}$ - значения признаков $i$-го объекта, $y_i$ - значение целевого признака $i$-го объекта, $\\ell$ - число объектов в обучающей выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный спуск\n",
    "Параметры $w_0, w_1, w_2, w_3$, по которым минимизируется среднеквадратичная ошибка, можно находить численно с помощью градиентного спуска.\n",
    "Градиентный шаг для весов будет выглядеть следующим образом:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{x_{ij}((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}},\\ j \\in \\{1,2,3\\}$$\n",
    "Здесь $\\eta$ - параметр, шаг градиентного спуска."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стохастический градиентный спуск\n",
    "Проблема градиентного спуска, описанного выше, в том, что на больших выборках считать на каждом шаге градиент по всем имеющимся данным может быть очень вычислительно сложно. \n",
    "В стохастическом варианте градиентного спуска поправки для весов вычисляются только с учетом одного случайно взятого объекта обучающей выборки:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2\\eta}{\\ell} {((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} {x_{kj}((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)},\\ j \\in \\{1,2,3\\},$$\n",
    "где $k$ - случайный индекс, $k \\in \\{1, \\ldots, \\ell\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормальное уравнение \n",
    "Нахождение вектора оптимальных весов $w$ может быть сделано и аналитически.\n",
    "Мы хотим найти такой вектор весов $w$, чтобы вектор $y$, приближающий целевой признак, получался умножением матрицы $X$ (состоящей из всех признаков объектов обучающей выборки, кроме целевого) на вектор весов $w$. То есть, чтобы выполнялось матричное уравнение:\n",
    "$$\\Large y = Xw$$\n",
    "Домножением слева на $X^T$ получаем:\n",
    "$$\\Large X^Ty = X^TXw$$\n",
    "Это хорошо, поскольку теперь матрица $X^TX$ - квадратная, и можно найти решение (вектор $w$) в виде:\n",
    "$$\\Large w = {(X^TX)}^{-1}X^Ty$$\n",
    "Матрица ${(X^TX)}^{-1}X^T$ - [*псевдообратная*](https://ru.wikipedia.org/wiki/Псевдообратная_матрица) для матрицы $X$. В NumPy такую матрицу можно вычислить с помощью функции [numpy.linalg.pinv](http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.linalg.pinv.html).\n",
    "\n",
    "Однако, нахождение псевдообратной матрицы - операция вычислительно сложная и нестабильная в случае малого определителя матрицы $X$ (проблема мультиколлинеарности). \n",
    "На практике лучше находить вектор весов $w$ решением матричного уравнения \n",
    "$$\\Large X^TXw = X^Ty$$Это может быть сделано с помощью функции [numpy.linalg.solve](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.linalg.solve.html).\n",
    "\n",
    "Но все же на практике для больших матриц $X$ быстрее работает градиентный спуск, особенно его стохастическая версия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инструкции по выполнению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В начале напишем простую функцию для записи ответов в текстовый файл. Ответами будут числа, полученные в ходе решения этого задания, округленные до 3 знаков после запятой. Полученные файлы после выполнения задания надо отправить в форму на странице задания на Coursera.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_answer_to_file(answer, filename):\n",
    "    with open(filename, 'w') as f_out:\n",
    "        f_out.write(str(round(answer, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Загрузите данные из файла *advertising.csv* в объект pandas DataFrame. [Источник данных](http://www-bcf.usc.edu/~gareth/ISL/data.html).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "adver_data = pd.read_csv('advertising.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Посмотрите на первые 5 записей и на статистику признаков в этом наборе данных.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  Radio  Newspaper  Sales\n",
       "1  230.1   37.8       69.2   22.1\n",
       "2   44.5   39.3       45.1   10.4\n",
       "3   17.2   45.9       69.3    9.3\n",
       "4  151.5   41.3       58.5   18.5\n",
       "5  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adver_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>147.042500</td>\n",
       "      <td>23.264000</td>\n",
       "      <td>30.554000</td>\n",
       "      <td>14.022500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>85.854236</td>\n",
       "      <td>14.846809</td>\n",
       "      <td>21.778621</td>\n",
       "      <td>5.217457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>74.375000</td>\n",
       "      <td>9.975000</td>\n",
       "      <td>12.750000</td>\n",
       "      <td>10.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>149.750000</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>25.750000</td>\n",
       "      <td>12.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>218.825000</td>\n",
       "      <td>36.525000</td>\n",
       "      <td>45.100000</td>\n",
       "      <td>17.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>296.400000</td>\n",
       "      <td>49.600000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TV       Radio   Newspaper       Sales\n",
       "count  200.000000  200.000000  200.000000  200.000000\n",
       "mean   147.042500   23.264000   30.554000   14.022500\n",
       "std     85.854236   14.846809   21.778621    5.217457\n",
       "min      0.700000    0.000000    0.300000    1.600000\n",
       "25%     74.375000    9.975000   12.750000   10.375000\n",
       "50%    149.750000   22.900000   25.750000   12.900000\n",
       "75%    218.825000   36.525000   45.100000   17.400000\n",
       "max    296.400000   49.600000  114.000000   27.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adver_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создайте массивы NumPy *X* из столбцов TV, Radio и Newspaper и *y* - из столбца Sales. Используйте атрибут *values* объекта pandas DataFrame.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Отмасштабируйте столбцы матрицы *X*, вычтя из каждого значения среднее по соответствующему столбцу и поделив результат на стандартное отклонение. Для определенности, используйте методы mean и std векторов NumPy (реализация std в Pandas может отличаться). Обратите внимание, что в numpy вызов функции .mean() без параметров возвращает среднее по всем элементам массива, а не по столбцам, как в pandas. Чтобы произвести вычисление по столбцам, необходимо указать параметр axis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.array(adver_data.iloc[:,0:3])\n",
    "y = np.array(adver_data.Sales)\n",
    "means, stds = X.mean(axis=0),X.std(axis=0)\n",
    "means, stds \n",
    "X = (X-means)/stds\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Добавьте к матрице *X* столбец из единиц, используя методы *hstack*, *ones* и *reshape* библиотеки NumPy. Вектор из единиц нужен для того, чтобы не обрабатывать отдельно коэффициент $w_0$ линейной регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "o=np.ones(shape=[X.shape[0],1])\n",
    "X=np.hstack((o,X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Реализуйте функцию *mserror* - среднеквадратичную ошибку прогноза. Она принимает два аргумента - объекты Series *y* (значения целевого признака) и *y\\_pred* (предсказанные значения). Не используйте в этой функции циклы - тогда она будет вычислительно неэффективной.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mserror(y, y_pred):\n",
    "    return np.sum((y-y_pred)**2)/len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales, если всегда предсказывать медианное значение Sales по исходной выборке? Запишите ответ в файл '1.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.34575\n"
     ]
    }
   ],
   "source": [
    "answer1 = mserror(y,np.ones(shape=y.shape)*np.median(y))\n",
    "print(answer1)\n",
    "write_answer_to_file(answer1, '1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Реализуйте функцию *normal_equation*, которая по заданным матрицам (массивам NumPy) *X* и *y* вычисляет вектор весов $w$ согласно нормальному уравнению линейной регрессии.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\Large w = {(X^TX)}^{-1}X^Ty$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normal_equation(X, y):\n",
    "    Xt=np.transpose(X)\n",
    "    Xi=np.linalg.inv(np.dot(Xt,X))\n",
    "    return np.dot(np.dot(Xi,Xt),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 14.0225       3.91925365   2.79206274  -0.02253861]\n"
     ]
    }
   ],
   "source": [
    "norm_eq_weights = normal_equation(X, y)\n",
    "print(norm_eq_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какие продажи предсказываются линейной моделью с весами, найденными с помощью нормального уравнения, в случае средних инвестиций в рекламу по ТВ, радио и в газетах? (то есть при нулевых значениях масштабированных признаков TV, Radio и Newspaper). Запишите ответ в файл '2.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.0225\n"
     ]
    }
   ],
   "source": [
    "answer2 = norm_eq_weights[0]\n",
    "print(answer2)\n",
    "write_answer_to_file(answer2, '2.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Напишите функцию *linear_prediction*, которая принимает на вход матрицу *X* и вектор весов линейной модели *w*, а возвращает вектор прогнозов в виде линейной комбинации столбцов матрицы *X* с весами *w*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_prediction(X, w):\n",
    "    return np.dot(X,w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью нормального уравнения? Запишите ответ в файл '3.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.78412631451\n"
     ]
    }
   ],
   "source": [
    "answer3 = mserror(y,linear_prediction(X,norm_eq_weights))\n",
    "print(answer3)\n",
    "write_answer_to_file(answer3, '3.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Напишите функцию *stochastic_gradient_step*, реализующую шаг стохастического градиентного спуска для линейной регрессии. Функция должна принимать матрицу *X*, вектора *y* и *w*, число *train_ind* - индекс объекта обучающей выборки (строки матрицы *X*), по которому считается изменение весов, а также число *$\\eta$* (eta) - шаг градиентного спуска (по умолчанию *eta*=0.01). Результатом будет вектор обновленных весов. Наша реализация функции будет явно написана для данных с 3 признаками, но несложно модифицировать для любого числа признаков, можете это сделать.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стохастический градиентный спуск\n",
    "Проблема градиентного спуска, описанного выше, в том, что на больших выборках считать на каждом шаге градиент по всем имеющимся данным может быть очень вычислительно сложно. \n",
    "В стохастическом варианте градиентного спуска поправки для весов вычисляются только с учетом одного случайно взятого объекта обучающей выборки:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2\\eta}{\\ell} {((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} {x_{kj}((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)},\\ j \\in \\{1,2,3\\},$$\n",
    "где $k$ - случайный индекс, $k \\in \\{1, \\ldots, \\ell\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stochastic_gradient_step(X, y, w, train_ind, eta=0.01):\n",
    "    xk=X[train_ind]\n",
    "    yk=y[train_ind]\n",
    "    wx_y=np.vdot(w,xk)-yk\n",
    "    l=len(y)\n",
    "    grad0 = 2/l*wx_y\n",
    "    grad1 = 2/l*xk[1]*wx_y\n",
    "    grad2 = 2/l*xk[2]*wx_y\n",
    "    grad3 = 2/l*xk[3]*wx_y\n",
    "    return  w - eta * np.array([grad0, grad1, grad2, grad3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Напишите функцию *stochastic_gradient_descent*, реализующую стохастический градиентный спуск для линейной регрессии. Функция принимает на вход следующие аргументы:**\n",
    "- X - матрица, соответствующая обучающей выборке\n",
    "- y - вектор значений целевого признака\n",
    "- w_init - вектор начальных весов модели\n",
    "- eta - шаг градиентного спуска (по умолчанию 0.01)\n",
    "- max_iter - максимальное число итераций градиентного спуска (по умолчанию 10000)\n",
    "- max_weight_dist - максимальное евклидово расстояние между векторами весов на соседних итерациях градиентного спуска,\n",
    "при котором алгоритм прекращает работу (по умолчанию 1e-8)\n",
    "- seed - число, используемое для воспроизводимости сгенерированных псевдослучайных чисел (по умолчанию 42)\n",
    "- verbose - флаг печати информации (например, для отладки, по умолчанию False)\n",
    "\n",
    "**На каждой итерации в вектор (список) должно записываться текущее значение среднеквадратичной ошибки. Функция должна возвращать вектор весов $w$, а также вектор (список) ошибок.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(X, y, w_init, eta=1e-2, max_iter=1e4,\n",
    "                                min_weight_dist=1e-8, seed=42, verbose=False):\n",
    "    # Инициализируем расстояние между векторами весов на соседних\n",
    "    # итерациях большим числом. \n",
    "    weight_dist = np.inf\n",
    "    # Инициализируем вектор весов\n",
    "    w = w_init\n",
    "    # Сюда будем записывать ошибки на каждой итерации\n",
    "    errors = []\n",
    "    # Счетчик итераций\n",
    "    iter_num = 0\n",
    "    # Будем порождать псевдослучайные числа \n",
    "    # (номер объекта, который будет менять веса), а для воспроизводимости\n",
    "    # этой последовательности псевдослучайных чисел используем seed.\n",
    "    np.random.seed(seed)\n",
    "        \n",
    "    # Основной цикл\n",
    "    while weight_dist > min_weight_dist and iter_num < max_iter:\n",
    "        # порождаем псевдослучайный \n",
    "        # индекс объекта обучающей выборки\n",
    "        random_ind = np.random.randint(X.shape[0])\n",
    "        # Ваш код здесь\n",
    "        y_pred=linear_prediction(X,w)\n",
    "        errors.append(mserror(y,y_pred))\n",
    "        w_new=stochastic_gradient_step(X,y,w,random_ind,eta)\n",
    "        weight_dist=np.linalg.norm(w_new-w)\n",
    "        w=w_new\n",
    "        iter_num+=1\n",
    "    return w, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Запустите $10^5$ итераций стохастического градиентного спуска. Укажите вектор начальных весов *w_init*, состоящий из нулей. Оставьте параметры  *eta* и *seed* равными их значениям по умолчанию (*eta*=0.01, *seed*=42 - это важно для проверки ответов).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w_init=np.array([0,0,0,0])\n",
    "stoch_grad_desc_weights, stoch_errors_by_iter = stochastic_gradient_descent(X,y,w_init,max_iter=1e5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим, чему равна ошибка на первых 50 итерациях стохастического градиентного спуска. Видим, что ошибка не обязательно уменьшается на каждой итерации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x2144bf63978>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEKCAYAAAAvlUMdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2144d879a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "plot(range(50), stoch_errors_by_iter[:50])\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Теперь посмотрим на зависимость ошибки от номера итерации для $10^5$ итераций стохастического градиентного спуска. Видим, что алгоритм сходится.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x2144d887438>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2144da9dda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "plot(range(len(stoch_errors_by_iter)), stoch_errors_by_iter)\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на вектор весов, к которому сошелся метод.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.40190566e+01,   3.91069256e+00,   2.78209808e+00,\n",
       "        -8.10462217e-03])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoch_grad_desc_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на среднеквадратичную ошибку на последней итерации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7844125883527591"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoch_errors_by_iter[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью градиентного спуска? Запишите ответ в файл '4.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.78441258841\n"
     ]
    }
   ],
   "source": [
    "y_pred=linear_prediction(X,stoch_grad_desc_weights)\n",
    "answer4 = mserror(y,y_pred)\n",
    "print(answer4)\n",
    "write_answer_to_file(answer4, '4.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответами к заданию будут текстовые файлы, полученные в ходе этого решения. Обратите внимание, что отправленные файлы не должны содержать пустую строку в конце. Данный нюанс является ограничением платформы Coursera. Мы работаем над исправлением этого ограничения.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
